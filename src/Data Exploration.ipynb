{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dill'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-57fe68194624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dill'"
     ]
    }
   ],
   "source": [
    "#Packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data, change directory to your corresponding directories\n",
    "#tag = pd.read_csv(\"C:/Users/cos00/Desktop/Nuclear/APAN5900/Tag Data Final.csv\")\n",
    "tag = pd.read_csv('~/Desktop/APAN5900/Tag Data Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(tag) #dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag.describe()  #summary of tag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(tag['MI'].notnull()) #only 1920not null value for MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert time column from string to time\n",
    "tag['Time'] = [datetime.strptime(x, '%m/%d/%Y %H:%M:%S') for x in tag['Time'] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract tag entries with MI value\n",
    "tag_MI = tag[tag['MI'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_MI.head() #glimpse of new tag_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(tag_MI) #dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#------exploratory analysis-----------\n",
    "#plot of MI\n",
    "plt.hist(tag_MI['MI'], bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scatter plot of some variables against MI\n",
    "plt.scatter(tag_MI['MI'], tag_MI['P1:FC70104'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(tag_MI['MI'], tag_MI['P1:FC70113'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(tag_MI['MI'], tag_MI['P1:FC70116'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#number of observations for each product grade\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(12,8)\n",
    "tag_MI['ProdGrade'].value_counts().plot(kind='bar') #1203K is most dominant product grade\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#heat map column 2 to 21\n",
    "tag_cor1 = tag.iloc[:,2:21]\n",
    "sns.heatmap(tag_cor1.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':14})\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(22,18)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#heat map column 22 to 41\n",
    "tag_cor2 = tag.iloc[:,np.r_[2, 22:41]]\n",
    "sns.heatmap(tag_cor2.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':14})\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(22,18)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#heat map column 42 to 61\n",
    "tag_cor3 = tag.iloc[:,np.r_[2, 42:61]]\n",
    "sns.heatmap(tag_cor3.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':14})\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(22,18)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#time series plot of MI value\n",
    "time = tag_MI['Time']\n",
    "mi = tag_MI['MI']\n",
    "plt.plot(time,mi)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(18,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take a close look at what is going on at the spike\n",
    "tag_MI.loc[(tag_MI['Time'] >= '2018-11-10') & (tag_MI['Time'] <= '2018-11-11')] \n",
    "#spike occurs on 2018-11-10 19:45 and 19:45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take a close look at what is going on at the spike\n",
    "tag_MI.loc[(tag_MI['Time'] >= '2019-05-19') & (tag_MI['Time'] <= '2019-06-10')]\n",
    "#it seems like spike occurs in late May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#zoom in left side of spike\n",
    "tag_left = tag_MI.loc[(tag_MI['Time'] >= '2018-11-10 09:15:00') & (tag_MI['Time'] <= '2018-11-12')]\n",
    "plt.plot(tag_left['Time'],tag_left['MI'])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(14,11)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,55])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MI mean value by different progrades\n",
    "Prograde_MI = tag_MI.groupby(['ProdGrade']).mean() #check mean MI for each Prograde\n",
    "plt.barh(Prograde_MI.index, Prograde_MI['MI'], color = 'orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The tallest spike is of product 4100N, which has mean MI of 7.5. It is clearly an outlier that needs to be removed.\n",
    "#second tallest spike is of 1102KR with mean MI of less than 5, remove this as well\n",
    "#They can be removed since neither of these product grades has too few values\n",
    "tag_MI = tag_MI[(tag_MI['MI'] != 52.88) & (tag_MI['MI'] != 25.14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----time series analysis------\n",
    "\n",
    "#preprocesing\n",
    "tag_Time = tag_MI[['Time', 'MI']]\n",
    "#tag_Time = tag_Time.groupby('Time')\n",
    "tag_Time = tag_Time.set_index('Time')\n",
    "tag_Time.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mean o mi\n",
    "MI_time = tag_Time['MI'].resample('MS').mean()\n",
    "MI_time['2018':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot seasonality and residual\n",
    "rcParams['figure.figsize'] = 18, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(MI_time, freq = 11, model='additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show() #no trend, this is not time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------test modeling-----------\n",
    "\n",
    "#split train and test\n",
    "train, test = train_test_split(tag_MI, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#pre-processing, use all numeric predicators\n",
    "X_train = train.drop([\"Time\", \"ProdGrade\", \"MI\"],axis=1)\n",
    "Y_train = train[\"MI\"]\n",
    "X_test = test.drop([\"Time\", \"ProdGrade\", \"MI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. linear model with all predicators\n",
    "lm_model = LinearRegression().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check accuracy\n",
    "lm_model.score(X_train, Y_train) #check r squared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "MI_lm = lm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check rmse\n",
    "mean_squared_error(test['MI'], MI_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many value do we get right exactly if we round to nearest 1 decimal   \n",
    "pred_round_lm = pd.DataFrame(list(np.round(MI_lm,1)), round(test['MI'],1))\n",
    "pred_round_lm.columns = ['predicted']\n",
    "np.shape(pred_round_lm.loc[pred_round_lm['predicted'] == \n",
    "                           pred_round_lm.index])[0]/(np.shape(test)[0])\n",
    "#3% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. linear model with some predicators (coef >= abs(0.1))\n",
    "predicators_used = ['P1:FC70113','P1:FC70310','P1:FFC70106','P1:FR70106','P1:QIA701001', 'P1:PR70200', 'P1:R700RECYCLEB', \n",
    "                     'P1:TI70141', 'P1:TI70304','P1:TR70104','P1:TR70201','P1:TR70305']\n",
    "X_train_lm = X_train[predicators_used]\n",
    "X_test_lm = X_test[predicators_used]\n",
    "lm_model2 = LinearRegression().fit(X_train_lm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check accuracy\n",
    "lm_model2.score(X_train_lm, Y_train) #check r squared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "MI_lm2 = lm_model2.predict(X_test_lm)\n",
    "#check rmse\n",
    "mean_squared_error(test['MI'], MI_lm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MI_lm2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-81fbd24af3d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#how many value do we get right exactly if we round to nearest 1 decimal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_round_lm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMI_lm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_round_lm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m np.shape(pred_round_lm2.loc[pred_round_lm2['predicted'] == \n\u001b[1;32m      5\u001b[0m                            pred_round_lm2.index])[0]/(np.shape(test)[0])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MI_lm2' is not defined"
     ]
    }
   ],
   "source": [
    "#how many value do we get right exactly if we round to nearest 1 decimal   \n",
    "pred_round_lm2 = pd.DataFrame(list(np.round(MI_lm2,1)), round(test['MI'],1))\n",
    "pred_round_lm2.columns = ['predicted']\n",
    "np.shape(pred_round_lm2.loc[pred_round_lm2['predicted'] == \n",
    "                           pred_round_lm2.index])[0]/(np.shape(test)[0])\n",
    "#4.9% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-91f3b6213b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#3. Linear model with some predicators plus their interactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtag_cor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#all correlations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtag_cor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_cor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicators_used\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicators_used\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#subset ronly predictors we used (>= |0.2|)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tag' is not defined"
     ]
    }
   ],
   "source": [
    "#3. Linear model with some predicators plus their interactions\n",
    "tag_cor = tag.corr() #all correlations\n",
    "tag_cor = tag_cor[predicators_used].loc[predicators_used] #subset ronly predictors we used (>= |0.2|)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print interactions\n",
    "for index, row in tag_cor.iterrows():\n",
    "    colinear = row[(row >= abs(0.4)) & (row < 1)]\n",
    "    print(index + \": \")\n",
    "    print(colinear.index)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine interactions to our column\n",
    "tag_MI_int = tag_MI\n",
    "tag_MI_int['P1:FC70310 x P1:FR70106'] = tag_MI_int['P1:FC70310'] * tag_MI_int['P1:FR70106']\n",
    "tag_MI_int['P1:PR70200 x P1:TR70305'] = tag_MI_int['P1:PR70200'] * tag_MI_int['P1:TR70305']\n",
    "tag_MI_int['P1:R700RECYCLEB x P1:FR70106'] = tag_MI_int['P1:R700RECYCLEB'] * tag_MI_int['P1:FR70106']\n",
    "tag_MI_int['P1:R700RECYCLEB x P1:TR70201'] = tag_MI_int['P1:R700RECYCLEB'] * tag_MI_int['P1:TR70201']\n",
    "tag_MI_int['P1:R700RECYCLEB x P1:TR70305'] = tag_MI_int['P1:R700RECYCLEB'] * tag_MI_int['P1:TR70305']\n",
    "tag_MI_int['P1:TI70141 x P1:TI70304'] = tag_MI_int['P1:TI70141'] * tag_MI_int['P1:TI70304']\n",
    "tag_MI_int['P1:TI70141 x P1:TR70201'] = tag_MI_int['P1:TI70141'] * tag_MI_int['P1:TR70201']\n",
    "tag_MI_int['P1:TI70141 x P1:TR70305'] = tag_MI_int['P1:TI70141'] * tag_MI_int['P1:TR70305']  \n",
    "tag_MI_int['P1:TI70304 x P1:TR70201'] = tag_MI_int['P1:TI70304'] * tag_MI_int['P1:TR70201'] \n",
    "tag_MI_int['P1:TI70304 x P1:TR70305'] = tag_MI_int['P1:TI70304'] * tag_MI_int['P1:TR70305'] \n",
    "tag_MI_int['P1:TR70201 x P1:TR70305'] = tag_MI_int['P1:TR70201'] * tag_MI_int['P1:TR70305']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modeling\n",
    "interactions_used = ['P1:FC70310 x P1:FR70106','P1:PR70200 x P1:TR70305','P1:R700RECYCLEB x P1:FR70106','P1:R700RECYCLEB x P1:TR70201',\n",
    "                    'P1:R700RECYCLEB x P1:TR70305','P1:TI70141 x P1:TI70304','P1:TI70141 x P1:TR70201','P1:TI70141 x P1:TR70305',\n",
    "                    'P1:TI70304 x P1:TR70201','P1:TI70304 x P1:TR70305','P1:TR70201 x P1:TR70305']\n",
    "#preprocess\n",
    "train_int, test_int = train_test_split(tag_MI_int, test_size=0.3, random_state=42)\n",
    "X_train_int = train_int.drop([\"Time\", \"ProdGrade\", \"MI\"],axis=1)\n",
    "Y_train_int = train_int[\"MI\"]\n",
    "X_test_int = test_int.drop([\"Time\", \"ProdGrade\", \"MI\"],axis=1)\n",
    "X_train_int_lm = X_train_int[predicators_used + interactions_used]\n",
    "X_test_int_lm = X_test_int[predicators_used + interactions_used]\n",
    "#model\n",
    "lm_model3 = LinearRegression().fit(X_train_int_lm, Y_train_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check accuracy\n",
    "lm_model3.score(X_train_int_lm, Y_train_int) #check r squared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "MI_lm3 = lm_model3.predict(X_test_int_lm)\n",
    "#check rmse\n",
    "mean_squared_error(test_int['MI'], MI_lm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many value do we get right exactly if we round to nearest 1 decimal   \n",
    "pred_round_lm3 = pd.DataFrame(list(np.round(MI_lm3,1)), round(test['MI'],1))\n",
    "pred_round_lm3.columns = ['predicted']\n",
    "np.shape(pred_round_lm3.loc[pred_round_lm3['predicted'] == \n",
    "                           pred_round_lm3.index])[0]/(np.shape(test)[0])\n",
    "#6.6% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. linear regression with normalization\n",
    "X_train_norm = preprocessing.normalize(X_train)\n",
    "lm_model4 = LinearRegression().fit(X_train_norm, Y_train)\n",
    "#check accuracy\n",
    "lm_model4.score(X_train_norm, Y_train) #check r squared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "X_test_norm = preprocessing.normalize(X_test)\n",
    "MI_lm4 = lm_model4.predict(X_test_norm)\n",
    "#check rmse\n",
    "mean_squared_error(test['MI'], MI_lm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many value do we get right exactly if we round to nearest 1 decimal   \n",
    "pred_round_lm4 = pd.DataFrame(list(np.round(MI_lm4,1)), round(test['MI'],1))\n",
    "pred_round_lm4.columns = ['predicted']\n",
    "np.shape(pred_round_lm4.loc[pred_round_lm4['predicted'] == \n",
    "                           pred_round_lm4.index])[0]/(np.shape(test)[0])\n",
    "#4% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. linear regression of normalization with selected variables\n",
    "X_train_nm = X_train.apply(lambda x: (x - x.min()) / (x.max() - x.min())) #mannual normalization for each column\n",
    "X_train_nm['MI'] = train['MI']\n",
    "MI_cor = X_train_nm.corr()['MI']\n",
    "pred_used = MI_cor[(MI_cor >= abs(0.1)) & (MI_cor < 1)].index #predictors with >= abs0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_nm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-330564a71d8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_nm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_nm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_used\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlm_model_nm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#check accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlm_model_nm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#check r squared value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_nm' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_nm = X_train_nm[pred_used]\n",
    "lm_model_nm = LinearRegression().fit(X_train_nm, Y_train)\n",
    "#check accuracy\n",
    "lm_model_nm.score(X_train_nm, Y_train) #check r squared value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-238c3d958ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test_nm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#mannual normalization for each column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test_nm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_used\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMI_lm_nm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_model_nm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#check rmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "X_test_nm = X_test.apply(lambda x: (x - x.min()) / (x.max() - x.min())) #mannual normalization for each column\n",
    "X_test_nm = X_test[pred_used]\n",
    "MI_lm_nm = lm_model_nm.predict(X_test_nm)\n",
    "#check rmse\n",
    "mean_squared_error(test['MI'], MI_lm_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bf6d2f02ef4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#6. linear regression with standardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlm_model5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#check accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlm_model5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#check r squared value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#6. linear regression with standardize\n",
    "X_train_scale = preprocessing.scale(X_train)\n",
    "lm_model5 = LinearRegression().fit(X_train_scale, Y_train)\n",
    "#check accuracy\n",
    "lm_model5.score(X_train_scale, Y_train) #check r squared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b50424ea14ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mMI_lm5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_model5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#check rmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMI_lm5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "X_test_scale = preprocessing.scale(X_test)\n",
    "MI_lm5 = lm_model5.predict(X_test_scale)\n",
    "#check rmse\n",
    "mean_squared_error(test['MI'], MI_lm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MI_lm5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-803e7a431631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#how many value do we get right exactly if we round to nearest 1 decimal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_round_lm5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMI_lm5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_round_lm5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m np.shape(pred_round_lm5.loc[pred_round_lm5['predicted'] == \n\u001b[1;32m      5\u001b[0m                            pred_round_lm5.index])[0]/(np.shape(test)[0])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MI_lm5' is not defined"
     ]
    }
   ],
   "source": [
    "#how many value do we get right exactly if we round to nearest 1 decimal   \n",
    "pred_round_lm5 = pd.DataFrame(list(np.round(MI_lm5,1)), round(test['MI'],1))\n",
    "pred_round_lm5.columns = ['predicted']\n",
    "np.shape(pred_round_lm5.loc[pred_round_lm5['predicted'] == \n",
    "                           pred_round_lm5.index])[0]/(np.shape(test)[0])\n",
    "#4.7% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7. random forest\n",
    "random_forest = RandomForestRegressor(n_estimators=500)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "random_forest.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checkaccuracy\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "MI_rf = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check rmse\n",
    "mean_squared_error(test['MI'], MI_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many value do we get right exactly if we round to nearest 1 decimal   \n",
    "pred_round_rf = pd.DataFrame(list(np.round(MI_rf,1)), round(test['MI'],1))\n",
    "pred_round_rf.columns = ['predicted']\n",
    "np.shape(pred_round_lm3.loc[pred_round_rf['predicted'] == \n",
    "                           pred_round_rf.index])[0]/(np.shape(test)[0])\n",
    "#10.2% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importance plot\n",
    "feat_importances = pd.Series(random_forest.feature_importances_, index=X_train.columns)\n",
    "feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8. random forest with selected variables from importance plot \n",
    "X_train_rm = X_train[['P1:FFC70113', 'P1:FR70106','P1:FFC70106','P1:QIA701001','P1:FC70113']]\n",
    "X_test_rm = X_test[['P1:FFC70113', 'P1:FR70106','P1:FFC70106','P1:QIA701001','P1:FC70113']]\n",
    "random_forest.fit(X_train_rm, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train_rm, Y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "MI_rf2 = random_forest.predict(X_test_rm)\n",
    "#check rmse\n",
    "mean_squared_error(test['MI'], MI_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many value do we get right exactly if we round to nearest 1 decimal\n",
    "pred_round_rf2 = pd.DataFrame(list(np.round(MI_rf2,1)), round(test['MI'],1))\n",
    "pred_round_rf2.columns = ['predicted']\n",
    "np.shape(pred_round_rf.loc[pred_round_rf2['predicted'] == \n",
    "                           pred_round_rf2.index])[0]/(np.shape(test)[0])\n",
    "#9.2 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9. boosting\n",
    "boosting = GradientBoostingRegressor(n_estimators=500, max_depth=2)\n",
    "boosting.fit(X_train, Y_train)\n",
    "boosting.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "MI_gb = boosting.predict(X_test)\n",
    "#check rmse\n",
    "mean_squared_error(test['MI'], MI_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many value do we get right exactly if we round to nearest 1 decimal\n",
    "pred_round_gb = pd.DataFrame(list(np.round(MI_gb,1)), round(test['MI'],1))\n",
    "pred_round_gb.columns = ['predicted']\n",
    "np.shape(pred_round_gb.loc[pred_round_gb['predicted'] == \n",
    "                           pred_round_gb.index])[0]/(np.shape(test)[0])\n",
    "#9.4 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
